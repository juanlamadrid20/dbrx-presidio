{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d58db4b-5c33-4860-9b23-0aba4b5b23f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install presidio_analyzer presidio_anonymizer\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a59d98bd-af3f-4d9c-973b-fce5a3b4d3fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai --upgrade\n",
    "# %pip install databricks-genai\n",
    "%pip install databricks-genai-inference\n",
    "# %pip install mlflow\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3da0b4c4-8c27-420c-bfd2-ee7d2f55eae5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "import json\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "databricks_token = mlflow.utils.databricks_utils.get_databricks_host_creds().token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56026db9-c053-4d7d-9ada-8f288c943054",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from presidio_analyzer import EntityRecognizer, RecognizerResult, AnalyzerEngine, RecognizerRegistry\n",
    "import mlflow\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "\n",
    "class DBRXRecognizer(EntityRecognizer):\n",
    "    def __init__(self, model=\"databricks-dbrx-instruct\", api_key=None, supported_entities=None):\n",
    "        self.model = model\n",
    "        self.api_key = api_key\n",
    "        self.supported_language = \"en\" \n",
    "        self.supported_entities = supported_entities if supported_entities else self.ENTITIES\n",
    "        self.client = OpenAI(\n",
    "            api_key=self.api_key,\n",
    "            base_url=\"https://e2-demo-field-eng.cloud.databricks.com/serving-endpoints\"\n",
    "        )\n",
    "        \n",
    "        super().__init__(\n",
    "            supported_entities=self.supported_entities,\n",
    "            supported_language=self.supported_language,\n",
    "            name=\"DBRX Recognizer\",\n",
    "        )\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"Load the model, not used as model is loaded during initialization.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_supported_entities(self) -> List[str]:\n",
    "        \"\"\"Return supported entities by this model.\"\"\"\n",
    "        return self.supported_entities\n",
    "    \n",
    "    # [{{\"type\": \"PERSON\", \"start\": \"10\", \"end\": \"14\", \"score\": \"1.0\"}}, {{\"type\": \"LOCATION\", \"start\": \"27\", \"end\": \"37\", \"score\": \"1.0\"}}]\n",
    "\n",
    "    def analyze(self, text, entities, language=\"en\", nlp_artifacts=None) -> List[RecognizerResult]:\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "            Your role is to identify and list personally identifiable information such as names, locations, and organizations in the given text.\n",
    "\n",
    "            Instructions:\n",
    "\n",
    "            Valid types in the entity is PERSON, LOCATION, ORGANIZATION.\n",
    "            PERSON: is for people \n",
    "            LOCATION: is physical/geographic locations\n",
    "            ORGANIZATION: is names of entities such as companies, etc \n",
    "\n",
    "            Your response should be xml with findings and nothing else. No commentary or additional explanations. \n",
    "            Here is an example of how you should respond:\n",
    "            <answer>\n",
    "                <entities>\n",
    "                    <entity>\n",
    "                        <type>PERSON</type>\n",
    "                        <start>10</start>\n",
    "                        <end>14</end>\n",
    "                        <score>1.0</score>\n",
    "                    </entity>\n",
    "                    <entity>\n",
    "                        <type>LOCATION</type>\n",
    "                        <start>27</start>\n",
    "                        <end>37</end>\n",
    "                        <score>1.0</score>\n",
    "                    </entity>\n",
    "                </entities>\n",
    "            </answer>\n",
    "\n",
    "            \n",
    "            The score is your level of confidence for the detected personally identifiable information.\n",
    "            Provide nothing else in the response other than the findings array, no commentary, explanations, or anything other than array response.\n",
    "            input: my name is juan and I live in New Jersey, and I work at WHO\n",
    "            output: \n",
    "            <answer>\n",
    "            <entities>\n",
    "                <entity>\n",
    "                    <type>PERSON</type>\n",
    "                    <start>12</start>\n",
    "                    <end>16</end>\n",
    "                    <item>juan</item>\n",
    "                    <score>1.0</score>\n",
    "                </entity>\n",
    "                <entity>\n",
    "                    <type>LOCATION</type>\n",
    "                    <start>27</start>\n",
    "                    <end>37</end>\n",
    "                    <item>New Jersey</item>\n",
    "                    <score>1.0</score>\n",
    "                </entity>\n",
    "                <entity>\n",
    "                    <type>ORGANIZATION</type>\n",
    "                    <start>12</start>\n",
    "                    <end>16</end>\n",
    "                    <item>WHO</item>\n",
    "                    <score>1.0</score>\n",
    "                </entity>\n",
    "                </entities>\n",
    "            </answer>\n",
    "            input: {text}\n",
    "            output: \n",
    "        \"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI system helping detect, classify, and anonymize sensitive PII data\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=self.model,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        detected_entities = self.parse_response(text, response)\n",
    "        return detected_entities\n",
    "\n",
    "    def find_start_end_all(self, input_string, search_string):\n",
    "        matches = []\n",
    "        # Perform case-insensitive search\n",
    "        for match in re.finditer(re.escape(search_string), input_string, re.IGNORECASE):\n",
    "            start_position = match.start()\n",
    "            end_position = match.end()\n",
    "            matches.append((start_position, end_position))\n",
    "        return matches\n",
    "\n",
    "\n",
    "    # Use regular expression to extract XML content\n",
    "    def parse_response(self, input_text, response):\n",
    "        completion_text = response.choices[0].message.content\n",
    "        xml_match = re.search(r'<answer>.*</answer>', completion_text, re.DOTALL)\n",
    "        if xml_match:\n",
    "            xml_content = xml_match.group(0)\n",
    "            root = ET.fromstring(xml_content)\n",
    "            entities = {}\n",
    "            for entity in root.findall('.//entity'):\n",
    "                entitiy_key = f\"{entity.find('type').text}/{entity.find('item').text}\"\n",
    "                entity_data = {\n",
    "                    'type': entity.find('type').text,\n",
    "                    'item': entity.find('item').text,\n",
    "                    'score': float(entity.find('score').text)\n",
    "                }\n",
    "                entities[entitiy_key] = entity_data\n",
    "            final_list = []\n",
    "            for k, v in entities.items():\n",
    "                occurrences = self.find_start_end_all(input_text, v[\"item\"])\n",
    "                for (start, end) in occurrences:\n",
    "                    print({\n",
    "                        \"entity_type\":v[\"type\"],\n",
    "                            \"start\":start,\n",
    "                            \"end\":end,\n",
    "                            \"score\": v[\"score\"],\n",
    "                            \"analysis_explanation\":f\"Found item: {v['item']}\"\n",
    "                    })\n",
    "                    final_list.append(RecognizerResult(\n",
    "                            entity_type= v[\"type\"],\n",
    "                            start=start,\n",
    "                            end=end,\n",
    "                            score=v[\"score\"],\n",
    "                            analysis_explanation=f\"Found item: {v['item']}\"\n",
    "                        ))\n",
    "            return final_list\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57136635-1501-43ea-94f2-3bc258e10079",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Usage example\n",
    "api_key = mlflow.utils.databricks_utils.get_databricks_host_creds().token\n",
    "supported_entities = [\"PERSON\", \"LOCATION\", \"ORGANIZATION\"]\n",
    "\n",
    "openai_recognizer = DBRXRecognizer(model=\"databricks-dbrx-instruct\", api_key=api_key, supported_entities=supported_entities)\n",
    "\n",
    "registry = RecognizerRegistry()\n",
    "registry.add_recognizer(openai_recognizer)\n",
    "\n",
    "analyzer = AnalyzerEngine(registry=registry)\n",
    "\n",
    "# text = \"Hello, my name is Juan and I live in New Jersey and work for Databricks.\"\n",
    "text = \"Hello, my name is Juan and I live in New Jersey and am playing baseball. Jenny is going to Starbucks too. Hmm maybe I wonder if Databricks has a Starbucks located inside it. What about Estee? Do they want some coffee. Toby seemed like he wanted some coffee.\"\n",
    "\n",
    "results = analyzer.analyze(text=text, language=\"en\", return_decision_process=True)\n",
    "\n",
    "print(\"final results -> \\n \")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b10cd678-48ee-418b-bfec-b66531c1d7c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c30b018e-d3c8-4e3e-bd18-26e195b2b3a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "dbrx_presidio_recognizer_xml",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
